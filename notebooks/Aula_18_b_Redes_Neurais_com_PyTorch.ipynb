{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/storopoli/ciencia-de-dados/master?filepath=notebooks%2FAula_18_b__Redes_Neurais_com_PyTorch.ipynb)\n",
    "<br>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/storopoli/ciencia-de-dados/blob/master/notebooks/Aula_18_b_Redes_Neurais_com_PyTorch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neurais com PyTorch\n",
    "\n",
    "**Objetivos**: Aprender Redes Neurais Artificiais (RNA) usando a biblioteca `PyTorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "[**PyTorch**](https://www.pytorch.org/) é uma biblioteca de código aberto para aprendizado de máquina aplicável a uma ampla variedade de tarefas. Foi criada pelo **Facebook** em 2016 é a principal biblioteca para criação e treinamento de redes neurais artificiais. A API toda é escrita em Python mas é executada em C++ na CPU ou em CUDA na GPU.\n",
    "\n",
    "No momento que eu escrevo esse tutorial (Abril de 2021), PyTorch está superando o TensorFlow (Google) em desempenho e adoção de uso. Isso acontece tanto na [academia](http://horace.io/pytorch-vs-tensorflow/) (mensurado pela adoção de artigos científicos nos principais encontros científicos de Aprendizagem Profunda e Aprendizagem de Márquina) quanto na [indústria](https://www.infoworld.com/article/3597904/why-enterprises-are-turning-from-tensorflow-to-pytorch.html) (mensurado pela adoção de grandes e renomadas empresas de tecnologia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/u7x8RXwLKcA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fdba84da730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('u7x8RXwLKcA', width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## O que é uma Rede Neural Artificial?\n",
    "\n",
    "Redes neurais artificiais (RNAs) são modelos computacionais inspirados pelo sistema nervoso central (em particular o cérebro) que são capazes de realizar o aprendizado de máquina bem como o reconhecimento de padrões. Redes neurais artificiais geralmente são apresentadas como sistemas de \"neurônios interconectados, que podem computar valores de entradas\", simulando o comportamento de redes neurais biológicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/redes_neurais.jpeg\" alt=\"redes neurais\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Como a rede neural aprende?\n",
    "\n",
    "Em cada neurônio há uma função de ativação (*activation function*) que processa uma combinação linear entre inputs e pesos sinápticos, gerando assim um sinal de saída.\n",
    "\n",
    "A informação flui da *input layer* para as *hidden layers* e por fim para a *output layer*. Nesse fluxo os inputs de dados da *input layer* são alimentados para os neurônios das *hidden layers* que por fim alimentam o neurônio final da *output layer*.\n",
    "\n",
    "A primeira passada de informação (propagação) pela rede é geralmente feita com parâmetros aleatórios para as funções de ativação dos neurônios.\n",
    "\n",
    "Ao realizar a propagação, chamada de *feed forward*, temos sinais de saídas nos neurônios da output layer. \n",
    "\n",
    "No fim da propagação, a função custo (uma métrica de erro) é calculada e o modelo então ajusta os parâmetros dos neurônios na direção de um menor custo (por meio do gradiente - derivada multivariada).\n",
    "\n",
    "Assim uma nova propagação é gerada e a numa nova função custo e calculada. Assim como é realizado a atualização dos parâmetros dos neurônios.\n",
    "\n",
    "O nome desse algoritmo é **Retro-propagação** (*Backpropagation*). E cada vez que ele é executado denomina-se como época (*epoch*). E quandos as épocas estabelecidas se encerram, a rede neural encerra o seu treinamento/aprendizagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/backpropagation.gif\" alt=\"backpropagation\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Funções de Ativação\n",
    "\n",
    "| **Sigmoid**                                                  | **Tanh**                                                     | **ReLU**                                                     | **Leaky ReLU**                                               |\n",
    "| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| $g(z)=\\frac{1}{1+e^{-z}}$                                    | $g(z)=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$                     | $g(z)=\\max (0, z)$                                           | $\\begin{array}{c}{g(z)=\\max (\\epsilon z, z)} \\\\ {\\text { com } \\epsilon \\ll 1}\\end{array}$ |\n",
    "| ![Illustration](images/sigmoid.png) | ![Illustration](images/tanh.png) | ![Illustration](images/relu.png) | ![Illustration](images/leaky-relu.png) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estruturação dos módulos de PyTorch\n",
    "\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "* [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) - Tensores (arrays N-D)\n",
    "* [`torch.nn`](https://pytorch.org/docs/stable/nn.html) - Redes Neurais (_**N**eural **N**etworks_)\n",
    "* [`torch.optim`](https://pytorch.org/docs/stable/optim.html) - Otimização (_**Optim**ization_)\n",
    "* [`torch.data`](https://pytorch.org/docs/stable/data.html) - *Datasets* e Ferramentas de Streaming de Dados\n",
    "* [`torch.autograd`](https://pytorch.org/docs/stable/autograd.html) - Diferenciação Automática (_**Auto**matic Differentiation_)\n",
    "* [`torch.vision`](https://pytorch.org/docs/stable/torchvision/index.html) - Ferramentas de Manipulação de Imagens e Visão Computacional\n",
    "* [`torch.audio`](https://pytorch.org/audio/stable/index.html) - Ferramentas de Manipulação de Áudio\n",
    "* [`torch.jit`](https://pytorch.org/docs/stable/jit.html) - Compilação _**j**ust-**i**n-**t**time_ de modelos PyTorch em binários\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `torch.Tensor`\n",
    "\n",
    "* `NumPy` - `np.ndarray`\n",
    "* `pandas` - `pd.Series` e `pd.DataFrame`\n",
    "* `PyTorch` - `torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algoritmos de Otimização\n",
    "\n",
    "Keras possui diversos:\n",
    "* SGD\n",
    "* RMSprop\n",
    "* Adam\n",
    "* Adadelta\n",
    "* Adagrad\n",
    "* Adamax\n",
    "\n",
    "Os mais importantes são o SGD e o Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SGD - Stochastic Gradient Descent\n",
    "\n",
    "[`torch.optim.sgd()`](https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html):\n",
    "\n",
    "* `lr` - Taxa de Aprendizagem $\\eta > 0$\n",
    "* `momentum=0.0` - hyperparâmetro $\\geq 0$ que acelera o *gradient descent* na direção relevante e mitiga oscilações. \n",
    "* `nesterov=False` - `bool` para se aplica *Nesterov Momentum* ou não. *Nesterov Momentum* usa posições intermediárias do gradiente no cálculo do *momentum*. Proposto por Yuri Nesterov em 1983.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "<img src=\"images/momentum.gif\" alt=\"momentum\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adam\n",
    "\n",
    "Adam é um método de SGD que usa uma estimativa adaptativa dos momentos de primeira ordem e momentos de segunda ordem. Proposto por Kingma & Ba (2014).\n",
    "\n",
    "[`torch.optim.Adam()`](https://pytorch.org/docs/stable/_modules/torch/optim/adam.html):\n",
    "\n",
    "* `lr=0.001` - Taxa de Aprendizagem $\\eta > 0$\n",
    "* `betas=(0.9, 0.999)` - Uma tupla de valores:\n",
    "    1. `betas[0]` - decréscimo exponencial da estimativa dos momentos de primeira ordem\n",
    "    2. `betas[1]` - decréscimo exponencial da estimativa dos momentos de segunda ordem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "<img src=\"images/comparacao_otimizadores.gif\" alt=\"comparacao_otimizadores\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "<img src=\"images/opt1.gif\" alt=\"comparacao_otimizadores_2\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "<img src=\"images/opt2.gif\" alt=\"comparacao_otimizadores_3\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Funções Custo\n",
    "\n",
    "As funções custos se dividem em dois tipos:\n",
    "\n",
    "1. Funções Custo de **Classificação**\n",
    "2. Funções Custo de **Regressão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funcões Custo de Classificação\n",
    "\n",
    "Mais utilizadas\n",
    "\n",
    "\n",
    "* *Binary Cross-entropy* (Entropia cruzada binária): [`torch.nn.BCELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
    "* *Categorical Cross-entropy - Negative Log-Likelihood Loss* (Entropia cruzada categórica): [`torch.nn.NLLLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Funcões Custo de Regressão\n",
    "\n",
    "Mais utilizadas\n",
    "* MSE - *Mean Squared Error* (Erro quadrado médio): [`torch.nn.MSELoss()`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
    "* MAE - *Mean Absolute Error - $\\| . \\|_1$* (Erro absoluto médio): [`torch.nn.L1Loss())`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Como construir sua rede neural no PyTorch\n",
    "\n",
    "Construir redes neurais com o **PyTorch** é tão fácil quanto com **Keras**.\n",
    "\n",
    "Temos que criar uma Rede Neural a partir de uma classe [`nn.Module()`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=module#torch.nn.Module) e criar um construtor com o método `__init__()` e implementar todas as layers e propagações desejadas com o método `forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4) # primeira hidden layer\n",
    "        self.fc2 = nn.Linear(4, 1) # segunda hidden layer\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instancia o Model()\n",
    "model = Model()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemplo de Classificação Binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassBin(\n",
      "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClassBin(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(ClassBin, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 20) # primeira hidden layer\n",
    "        self.fc2 = nn.Linear(20, 1) # segunda hidden layer\n",
    "        self.sigmoid = nn.Sigmoid()      # output layer com ativação Sigmoid\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ClassBin()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemplo de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg(\n",
      "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Reg(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(Reg, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 20) # primeira hidden layer\n",
    "        self.fc2 = nn.Linear(20, 1) # segunda hidden layer output 1 único neurônio\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = Reg()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemplo de Multiclassificação (não-binária - acima de duas classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClass(\n",
      "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultiClass(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(MultiClass, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 20) # primeira hidden layer\n",
    "        self.fc2 = nn.Linear(20, 10) # segunda hidden layer\n",
    "        self.softmax = nn.Softmax(10)    # output layer com ativação ativação softmax com 10 classes\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = MultiClass()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Como treinar sua rede neural no PyTorch\n",
    "\n",
    "Uma vez especificado e instanciado o modelo, podemos manipulá-lo de maneira dinâmica. Não é preciso \"compilar\" que nem o TensorFlow/Keras. Escolhemos a função custo (`loss_fn`) como `nn.NLLLoss()` e também a taxa de aprendizagem $\\eta$ em `1e-6` e a quantidade de épocas a serem treinadas (`epochs`):\n",
    "\n",
    "```python\n",
    "model = Sua_rede_neural()\n",
    "loss_fn = nn.NLLLoss()\n",
    "learning_rate = 1e-6\n",
    "epochs = 100\n",
    "\n",
    "# Instânciar o Otimizador SGD\n",
    "optimizer = torch.optim.sgd(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    model.train() # Colocar o modelo em modo de treinamento (calcula os gradientes)\n",
    "    \n",
    "    # Propagação (Feed Forward)\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Calcular erro usando a função-custo\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zera os gradientes antes da Retro-propagação (Backpropagation)\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Retro-propagação (Backpropagation)\n",
    "    loss.backward()\n",
    "\n",
    "    # Atualização dos parâmetros\n",
    "    optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Como ajustar o treinamento sua rede neural no PyTorch\n",
    "\n",
    "* Batch Size\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Batch Size\n",
    "\n",
    "Tamanho do Batch (Srivastava et. al, 2014) de dados que passa por vez pela rede neural antes da atualização dos parâmetros pelo *backpropagation*. Tamanhos grandes resultam em instabilidade no treinamento. Geralmente usam-se potências de $2$ $(2,4,8,16,\\dots, 2^n)$.\n",
    "\n",
    "Em Abril de 2018, Yann LeCun, um dos principais pesquisadores sobre redes neurais e ganhador do \"nobel\" da computação (Prêmio Turing) twittou em resposta à um artigo empírico que mostrava diversos contextos de *batch size*:\n",
    ">\"Friends don't let friends use mini-batches larger than 32\"\n",
    "\n",
    "Então 32 é um valor empiricamente verificado que dá estabilidade ao treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para controlar como que os dados são inseridos no modelo e, logo, o Batch Size é preciso implementar um [`torch.utils.data.DataLoader()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader):\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import TorchDataset, DataLoader\n",
    "\n",
    "# Converter X e y para torch.Tensor\n",
    "X = torch.Tensor(X)\n",
    "y = torch.Tensor(y)\n",
    "\n",
    "# Um Dataset de Tensores - Array [X, y]\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "Argumentos do `DataLoader()`: \n",
    "\n",
    "* **`dataset`**: um `Dataset` PyTorch\n",
    "    * tem [vários tipos](https://pytorch.org/docs/stable/data.html)\n",
    "    * no nosso exemplo vou usar um simples [`TensorDataset`](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#TensorDataset) que é um wrapper de `np.ndarray` e `pd.Series` para `torch.Tensor`)\n",
    "* **batch_size**: `int` - tamanho do Batch Size, padrão é 1\n",
    "* **shuffle**: `bool` - se vai embaralhar os dados antes de enviar em batches ao modelo, padrão é `False`. Recomendo usar `shuffle=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dropout\n",
    "\n",
    "Uma medida de regularização na qual evita-se overfitting proposta por Hinton em 2012. *Dropout* é um algoritmo que especifica que a cada iteração de época do treino os neurônios possuem uma probabilidade de serem removidos (não utilizados) para a aprendizagem. Geralmente a probabilidade ideal fica em torno de 20% ($0.2$).\n",
    "\n",
    "Coloca-se como se fosse uma camada após a camada que deseja aplicar o dropout:\n",
    "\n",
    "```python\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(4, 4) ,  # hidden layer\n",
    "    nn.Dropout(0.2)    # dropout layer\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/dropout.gif\" alt=\"dropout\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo com o dataset Titanic\n",
    "\n",
    "Contém 891 passageiros reais do Titanic que afundou em 15/04/1912 matando 1502 de 2224 passageiros e tripulação que estavam a bordo.\n",
    "\n",
    "* `survived`: *dummy* `0` ou `1` \n",
    "* `pclass`: Classe do Passageiro\n",
    "    - `1`: Primeira Classe\n",
    "    - `2`: Segunda Classe\n",
    "    - `3`: Terceira Classe\n",
    "* `sex`: Sexo `male` ou `female`\n",
    "* `age`: Idade\n",
    "* `sibsp`: Número de Irmãos (*Siblings*) e Esposas (*spouse*) a bordo\n",
    "* `parch`: Número de pais/filhos a bordo\n",
    "* `fare`: Valor pago pela passagem em libras\n",
    "* `embarked`: Porto que embarcou\n",
    "    - `C`: Cherbourg\n",
    "    - `Q`: Queenstown\n",
    "    - `S`: Southampton)\n",
    "* `class`: Mesmo que `pclass` só que em texto\n",
    "* `adult_male`: *dummy* para `age > 16` e `sex == 'male'`\n",
    "* `deck`: Qual deck a cabine do passageiro se situava\n",
    "* `alive`: Mesmo que survived só que com `yes` ou `no`\n",
    "* `alone`: *dummy* para se viajava sozinho\n",
    "\n",
    ">Obs: usar `random_state = 123`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/titanic.png\" alt=\"titanic\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "feature_names = ['pclass', 'female', 'age', 'fare']\n",
    "titanic['female'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic.dropna(subset=feature_names, inplace=True)  #891 para 714\n",
    "\n",
    "X = titanic[feature_names].to_numpy()\n",
    "y = titanic['survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de X_train:  (535, 4)\n",
      "Tamanho de X_test:  (179, 4)\n",
      "Tamanho de y_train:  (535,)\n",
      "Tamanho de y_test:  (179,)\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape)\n",
    "print('Tamanho de X_test: ', X_test.shape)\n",
    "print('Tamanho de y_train: ', y_train.shape)\n",
    "print('Tamanho de y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassBin(\n",
      "  (linear1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ClassBin(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(ClassBin, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 4)  # primeira hidden layer\n",
    "        self.dropout1 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear2 = nn.Linear(4, 1)\n",
    "        self.dropout2 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ClassBin()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "epochs = 100\n",
    "batch_size = 32  # X_train 535 / 32 = 16.71 (então são 17 batches de 32)\n",
    "\n",
    "# Instânciar o Otimizador Adam\n",
    "optimizer = torch.optim.Adam(model.parameters()) # Não preciso de lr pq o adam já tem uma padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Converter X e y para torch.Tensor\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# Um Dataset de Tensores - Array [X, y]\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Custo Treino: 1.3683580160140991, Acurácia de Treino: 0.41869157552719116, Acurácia de Teste: 0.3966480493545532\n",
      "Época 2, Custo Treino: 0.7940693497657776, Acurácia de Treino: 0.5121495127677917, Acurácia de Teste: 0.4804469347000122\n",
      "Época 3, Custo Treino: 1.109289288520813, Acurácia de Treino: 0.6112149357795715, Acurácia de Teste: 0.6815642714500427\n",
      "Época 4, Custo Treino: 1.0027153491973877, Acurácia de Treino: 0.6710280179977417, Acurácia de Teste: 0.6983240246772766\n",
      "Época 5, Custo Treino: 0.9851495623588562, Acurácia de Treino: 0.6785046458244324, Acurácia de Teste: 0.7094972133636475\n",
      "Época 6, Custo Treino: 1.2008370161056519, Acurácia de Treino: 0.6747663617134094, Acurácia de Teste: 0.7094972133636475\n",
      "Época 7, Custo Treino: 0.9282795190811157, Acurácia de Treino: 0.663551390171051, Acurácia de Teste: 0.6927374005317688\n",
      "Época 8, Custo Treino: 0.8150954842567444, Acurácia de Treino: 0.663551390171051, Acurácia de Teste: 0.6759776473045349\n",
      "Época 9, Custo Treino: 0.7526323795318604, Acurácia de Treino: 0.6598131060600281, Acurácia de Teste: 0.6648044586181641\n",
      "Época 10, Custo Treino: 0.8639273643493652, Acurácia de Treino: 0.6560747623443604, Acurácia de Teste: 0.659217894077301\n",
      "Época 11, Custo Treino: 1.0564122200012207, Acurácia de Treino: 0.6299065351486206, Acurácia de Teste: 0.659217894077301\n",
      "Época 12, Custo Treino: 0.9652198553085327, Acurácia de Treino: 0.6242990493774414, Acurácia de Teste: 0.6424580812454224\n",
      "Época 13, Custo Treino: 0.7212202548980713, Acurácia de Treino: 0.6280373930931091, Acurácia de Teste: 0.6312848925590515\n",
      "Época 14, Custo Treino: 0.9061955809593201, Acurácia de Treino: 0.6186915636062622, Acurácia de Teste: 0.6256983280181885\n",
      "Época 15, Custo Treino: 0.8941261172294617, Acurácia de Treino: 0.6130841374397278, Acurácia de Teste: 0.6312848925590515\n",
      "Época 16, Custo Treino: 0.6766108870506287, Acurácia de Treino: 0.6112149357795715, Acurácia de Teste: 0.6256983280181885\n",
      "Época 17, Custo Treino: 0.8713364601135254, Acurácia de Treino: 0.6093457937240601, Acurácia de Teste: 0.6201117038726807\n",
      "Época 18, Custo Treino: 0.7139363288879395, Acurácia de Treino: 0.6093457937240601, Acurácia de Teste: 0.6201117038726807\n",
      "Época 19, Custo Treino: 0.7165648341178894, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6201117038726807\n",
      "Época 20, Custo Treino: 0.7452914118766785, Acurácia de Treino: 0.6093457937240601, Acurácia de Teste: 0.6089385747909546\n",
      "Época 21, Custo Treino: 0.7211087346076965, Acurácia de Treino: 0.6037383079528809, Acurácia de Teste: 0.6089385747909546\n",
      "Época 22, Custo Treino: 0.6485533714294434, Acurácia de Treino: 0.6037383079528809, Acurácia de Teste: 0.6089385747909546\n",
      "Época 23, Custo Treino: 0.7982053160667419, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 24, Custo Treino: 0.668830156326294, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6145251393318176\n",
      "Época 25, Custo Treino: 0.730624258518219, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6145251393318176\n",
      "Época 26, Custo Treino: 0.7477446794509888, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6145251393318176\n",
      "Época 27, Custo Treino: 0.7639482021331787, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6089385747909546\n",
      "Época 28, Custo Treino: 0.7237685918807983, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6089385747909546\n",
      "Época 29, Custo Treino: 0.7328380942344666, Acurácia de Treino: 0.6056074500083923, Acurácia de Teste: 0.6089385747909546\n",
      "Época 30, Custo Treino: 0.7162988781929016, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 31, Custo Treino: 0.6948999166488647, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 32, Custo Treino: 0.6974354386329651, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 33, Custo Treino: 0.708052933216095, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 34, Custo Treino: 0.6751804947853088, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 35, Custo Treino: 0.7265129089355469, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 36, Custo Treino: 0.7148376703262329, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 37, Custo Treino: 0.6964977383613586, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 38, Custo Treino: 0.7498747706413269, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 39, Custo Treino: 0.7052618861198425, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 40, Custo Treino: 0.685404360294342, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 41, Custo Treino: 0.7015621066093445, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 42, Custo Treino: 0.7097469568252563, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 43, Custo Treino: 0.6766629219055176, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 44, Custo Treino: 0.6924780011177063, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 45, Custo Treino: 0.7007544040679932, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 46, Custo Treino: 0.6939724087715149, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 47, Custo Treino: 0.7041869759559631, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 48, Custo Treino: 0.6952128410339355, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 49, Custo Treino: 0.6377813816070557, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 50, Custo Treino: 0.6826779842376709, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 51, Custo Treino: 0.6908867359161377, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 52, Custo Treino: 0.7239820957183838, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 53, Custo Treino: 0.6916226744651794, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 54, Custo Treino: 0.6889604330062866, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 55, Custo Treino: 0.692599356174469, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 56, Custo Treino: 0.7246362566947937, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 57, Custo Treino: 0.671638548374176, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 58, Custo Treino: 0.6793907284736633, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 59, Custo Treino: 0.6435508131980896, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 60, Custo Treino: 0.6859179139137268, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 61, Custo Treino: 0.6764505505561829, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 62, Custo Treino: 0.6934642195701599, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 63, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 64, Custo Treino: 0.7244027256965637, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 65, Custo Treino: 0.6584299206733704, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 66, Custo Treino: 0.6966009736061096, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 67, Custo Treino: 0.7410183548927307, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 68, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 69, Custo Treino: 0.6676005721092224, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 70, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 71, Custo Treino: 0.6973958015441895, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 72, Custo Treino: 0.6520102024078369, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 73, Custo Treino: 0.6456815600395203, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 74, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 75, Custo Treino: 0.6850940585136414, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 76, Custo Treino: 0.6803550720214844, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 77, Custo Treino: 0.6767157912254333, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 78, Custo Treino: 0.6943796277046204, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 79, Custo Treino: 0.7181797027587891, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 80, Custo Treino: 0.6773572564125061, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 81, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 82, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 83, Custo Treino: 0.7223894596099854, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 84, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 85, Custo Treino: 0.6958754062652588, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 86, Custo Treino: 0.6940509676933289, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 87, Custo Treino: 0.683402955532074, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 88, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 89, Custo Treino: 0.6868592500686646, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 90, Custo Treino: 0.6915785074234009, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 91, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 92, Custo Treino: 0.7047145962715149, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 93, Custo Treino: 0.7311670184135437, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 94, Custo Treino: 0.6647061705589294, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 95, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6033519506454468\n",
      "Época 96, Custo Treino: 0.6747017502784729, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 97, Custo Treino: 0.6931471824645996, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 98, Custo Treino: 0.6935837864875793, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 99, Custo Treino: 0.7516293525695801, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n",
      "Época 100, Custo Treino: 0.6654972434043884, Acurácia de Treino: 0.6074766516685486, Acurácia de Teste: 0.6089385747909546\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    model.train() # Colocar o modelo em modo de treinamento (calcula os gradientes)\n",
    "    \n",
    "    for data in train_loader:\n",
    "        # dar nome aos bois\n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "    \n",
    "        # Propagação (Feed Forward)\n",
    "        y_pred = model(X)\n",
    "    \n",
    "        # Calcular erro usando a função-custo\n",
    "        loss = loss_fn(y_pred, y.unsqueeze_(1)) # y precisa virar um Tensor com tamanho (batch_size, 1)\n",
    "\n",
    "        # Zera os gradientes antes da Retro-propagação (Backpropagation)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Retro-propagação (Backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualização dos parâmetros\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Calcular erro e acurácia de Treino\n",
    "    model.eval() # coloca o modelo em modo de avaliação (sem calcular gradientes)\n",
    "    train_pred = model(X_train)\n",
    "    train_pred = train_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "    train_acc = torch.sum(train_pred.flatten() == y_train) / train_pred.size(0)\n",
    "\n",
    "    # Calcular acurácia de Teste\n",
    "    test_pred = model(X_test)\n",
    "    test_pred = test_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "    test_acc = torch.sum(test_pred.flatten() == y_test) / test_pred.size(0)\n",
    "    \n",
    "    # Fim da Época\n",
    "    print(f\"Época {t + 1}, Custo Treino: {loss.item()}, Acurácia de Treino: {train_acc}, Acurácia de Teste: {test_acc}\")\n",
    "    \n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot acurácia de treino e validação\n",
    "plt.plot(train_accuracy)\n",
    "plt.plot(test_accuracy)\n",
    "plt.title('Acurácia do Modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treino', 'Teste'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Acurácia do Modelo\n",
    "\n",
    "Usar o comando `model.evaluate()`\n",
    "\n",
    "Para a métrica acurácia, retorna um score de acurácia `float` entre $0$ e $1$\n",
    "    \n",
    "> Obs: Regressão Logística acurácias: 0.69 Treino e 0.7 Teste\n",
    "\n",
    "> Obs: *Support Vector Machines* acurácias: 0.79 Treino e 0.75 Teste\n",
    "\n",
    "> Obs: Árvores de Decisão acurácias: 0.79 Treino e 0.79 Teste\n",
    "\n",
    "> Obs: Florestas Aleatórias acurácias: 0.84 Treino e 0.82 Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Treino: 0.6074766516685486\n",
      "\n",
      " ---------------------------\n",
      "\n",
      "Acurácia de Teste: 0.6089385747909546\n"
     ]
    }
   ],
   "source": [
    "model.eval() # coloca o modelo em modo de avaliação (sem calcular gradientes)\n",
    "\n",
    "train_pred = model(X_train)\n",
    "train_pred = train_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "train_acc = torch.sum(train_pred.flatten() == y_train) / train_pred.size(0)\n",
    "\n",
    "test_pred = model(X_test)\n",
    "test_pred = test_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "test_acc = torch.sum(test_pred.flatten() == y_test) / test_pred.size(0)\n",
    "\n",
    "print(f\"Acurácia de Treino: {train_acc}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referências\n",
    "\n",
    "* Hinton, Geoffrey, Nitish Srivastava, and Kevin Swersky. “Neural Networks for Machine Learning Lecture 6a Overview of Mini--Batch Gradient Descent,” 2012.\n",
    "* Kingma, Diederik P., and Jimmy Ba. “Adam: A Method for Stochastic Optimization,” December 22, 2014. https://arxiv.org/abs/1412.6980.\n",
    "* Nesterov, Y. A method of solving a convex programming problem with convergence rate O(1/sqr(k)). Soviet Mathematics Doklady, 27:372–376, 1983.\n",
    "* Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. “Dropout: A Simple Way to Prevent Neural Networks from Overfitting.” Journal of Machine Learning Research 15, no. 56 (2014): 1929–58."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "progress": true,
   "scroll": true,
   "slideNumber": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
