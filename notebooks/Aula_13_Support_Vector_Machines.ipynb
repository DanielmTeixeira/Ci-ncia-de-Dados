{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/storopoli/ciencia-de-dados/master?filepath=notebooks%2FAula_13_Support_Vector_Machines.ipynb)\n",
    "<br>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/storopoli/ciencia-de-dados/blob/master/notebooks/Aula_13_Support_Vector_Machines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# *Support Vector Machines* - SVM (Máquina de Vetores de Suporte)\n",
    "\n",
    "**Objetivos**: Aprender o que é SVM usando a biblioteca `Scikit-Learn`. Introduzir a técnica e os diferentes tipos de *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## O que é SVM?\n",
    "\n",
    "SVM é uma técnica de aprendizado supervisionado que encontra um hiperplano de separação entre os dados. Esta separação busca minimizar uma função custo maximizando a distância entre os pontos, assim separando-os de maneira mais eficiente. O hiperplano de separação pode ser linear ou não dependendo do kernel.\n",
    "\n",
    "\n",
    "<img src=\"images/support-vector-machines.png\" alt=\"support-vector-machines\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classificação e Regressão\n",
    "\n",
    "* Classificação: [`sklearn.svm.SVC()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* Regressão: [`sklearn.svm.LinearSVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hiperparâmetro $C$\n",
    "\n",
    "Quanto **menor** $C$ mais **tolerante** (e ampla) serão as **margens dos hiperplanos** de separação e mais **flexível** o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "# Criação de 100 pontos separáveis\n",
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  cluster_std=2, random_state=123)\n",
    "\n",
    "# Implementando SVM linear para níveis diferentes de C\n",
    "for C in [1e-1, 1e2, 1e3, 1e4]:\n",
    "    clf = SVC(kernel='linear', C=C)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "    \n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    # plot support vectors\n",
    "    ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "               linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.title(f\"Valor de $C$: {C}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 tipos de Kernels\n",
    "\n",
    "* Linear\n",
    "* Radial\n",
    "* Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Somente pegar as duas primeiras features para plotar em 2-D\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for kernel in ['linear', 'poly', 'rbf']:  # rbf - radial basis function\n",
    "    clf = SVC(kernel=kernel, gamma=10, C=1e4)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolor='k', s=20)\n",
    "\n",
    "    # Denotar com circulo o test set\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=80, facecolors='none',\n",
    "                zorder=10, edgecolor='k')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Colocar o resultado num plot colorido\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "    \n",
    "    # Gerar previsoes no Train Set\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = round(accuracy_score(y, y_pred), 3)\n",
    "\n",
    "    plt.title(kernel + f\" - Acurácia no Treinamento: {acc}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pré-processamento dos Dados\n",
    "\n",
    "SVM é extremamente sensível a dados não padronizados. Portanto é importante padronizar para que todas as variáveis preditoras tenham média $0$ e desvio padrão $1$.\n",
    "\n",
    "Para isso, usamos a função [`sklearn.preprocessing.StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Criação de 10.000 pontos separáveis\n",
    "X, y = make_blobs(n_samples=10000, centers=2,\n",
    "                  cluster_std=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = SVC(C=0.1, kernel='rbf', gamma=10)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = SVC(C=0.1, kernel='rbf', gamma=10)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo com o Dataset Titanic\n",
    "\n",
    "Contém 891 passageiros reais do Titanic que afundou em 15/04/1912 matando 1502 de 2224 passageiros e tripulação que estavam a bordo.\n",
    "\n",
    "* `survived`: *dummy* `0` ou `1` \n",
    "* `pclass`: Classe do Passageiro\n",
    "    - `1`: Primeira Classe\n",
    "    - `2`: Segunda Classe\n",
    "    - `3`: Terceira Classe\n",
    "* `sex`: Sexo `male` ou `female`\n",
    "* `age`: Idade\n",
    "* `sibsp`: Número de Irmãos (*Siblings*) e Esposas (*spouse*) a bordo\n",
    "* `parch`: Número de pais/filhos a bordo\n",
    "* `fare`: Valor pago pela passagem em libras\n",
    "* `embarked`: Porto que embarcou\n",
    "    - `C`: Cherbourg\n",
    "    - `Q`: Queenstown\n",
    "    - `S`: Southampton)\n",
    "* `class`: Mesmo que `pclass` só que em texto\n",
    "* `adult_male`: *dummy* para `age > 16` e `sex == 'male'`\n",
    "* `deck`: Qual deck a cabine do passageiro se situava\n",
    "* `alive`: Mesmo que survived só que com `yes` ou `no`\n",
    "* `alone`: *dummy* para se viajava sozinho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/titanic.png\" alt=\"titanic\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "feature_names = ['pclass', 'female', 'age', 'fare']\n",
    "titanic['female'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic.dropna(subset=feature_names, inplace=True)  #891 para 714\n",
    "\n",
    "X = titanic[feature_names].to_numpy()\n",
    "y = titanic['survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizando as variáveis preditoras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SVM de Classificação\n",
    "Usar a função do Scikit-Learn [`sklearn.svm.SVC()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    "#### Argumentos:\n",
    "* `C` - `float` - Hyperparâmetro de Regularização (tem que ser positivo)\n",
    "* `kernel` - `str` - Tipo do Kernel\n",
    "    * `linear` - Kernel Linear\n",
    "    * `poly` -  Kernel Polinomial\n",
    "    * `rbf` -  Kernel Radial \n",
    "* `gamma` - Coeficiente de Kernel para `poly` e `rbf`\n",
    "    * Padrão - `scale`\n",
    "* `random_state` - `int` - seed do gerador de número randômicos (replicabilidade)\n",
    "\n",
    "#### Retorna:\n",
    "* Objeto `estimator` do Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SVM de Regressão\n",
    "Usar a função do Scikit-Learn [`sklearn.svm.LinearSVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html)\n",
    "\n",
    "#### Argumentos:\n",
    "* `C` - `float` - Hyperparâmetro de Regularização (tem que ser positivo)\n",
    "* `kernel` - `str` - Tipo do Kernel\n",
    "    * `linear` - Kernel Linear\n",
    "    * `poly` -  Kernel Polinomial\n",
    "    * `rbf` -  Kernel Radial \n",
    "* `gamma` - Coeficiente de Kernel para `poly` e `rbf`\n",
    "    * Padrão - `scale`\n",
    "* `random_state` - `int` - seed do gerador de número randômicos (replicabilidade)\n",
    "\n",
    "#### Retorna:\n",
    "* Objeto `estimator` do Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=10, random_state=123)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Acurácia do Modelo\n",
    "Usar a função do Scikit-Learn [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "\n",
    "Retorna um score de acurácia `float` entre $0$ e $1$\n",
    "\n",
    "#### Argumentos\n",
    "* `y_true`: Classes Verdadeiras\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)\n",
    "* `y_pred`: Classes Previstas pelo Modelo\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)\n",
    "    \n",
    "> Obs: Regressão Logística acurácias: 0.69 Treino e 0.7 Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_true = y_train\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_true = y_test\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Acurácia de Treino: {round(accuracy_score(y_train_true, y_train_pred), 2)}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {round(accuracy_score(y_test_true, y_test_pred), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando vários *kernels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "for kernel in ['linear', 'poly', 'rbf']:\n",
    "    clf_kernel = SVC(kernel=kernel, random_state=123, C=10)\n",
    "    clf_kernel.fit(X_train, y_train)\n",
    "    print(f\"Acurácia de teste - Kernel {kernel}: {round(clf_kernel.score(X_test, y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mapa-conceitual](https://raw.githubusercontent.com/storopoli/ciencia-de-dados/master/Mapas%20Conceituais/14%20-%20Support%20Vector%20Machines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Atividade - SVM com o dataset [Iris](https://scikit-learn.org/stable/datasets/index.html#iris-dataset)\n",
    "\n",
    "Edgar Anderson coletou os dados para quantificar a variação morfológica das flores de íris de três espécies relacionadas.\n",
    "\n",
    "O conjunto de dados consiste em 50 amostras de cada uma das três espécies de Iris (Setosa, Virginica e Versicolor). Quatro características foram medidas em cada amostra (cm):\n",
    "\n",
    "* $N = 150$\n",
    "* Atributos: 10\n",
    "    * `sepal length (cm)` - Cumprimento da Sépala\n",
    "    * `sepal width (cm)` - Largura da Sépala\n",
    "    * `petal length (cm)` - Cumprimento da Pétala\n",
    "    * `petal width (cm)` - Largua da Sépala\n",
    "* Variável dependente: Tipo de espécie de Iris\n",
    "    * `0` - Setosa\n",
    "    * `1` - Virginica\n",
    "    * `2` Versicolor \n",
    "\n",
    "* Achar a acurácia do modelo e os respectivos coeficientes dos atributos ($\\theta_i$) e viés/constante ($\\theta_0$)\n",
    "\n",
    ">Obs: usar `test_size = 0.25` e `random_state = 123`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/iris-species.png\" alt=\"iris-sepals-petals\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Nomes dos Atributos: ', iris['feature_names'])\n",
    "print('Tamanho de X: ', X.shape,)\n",
    "print('Tamanho de y: ', y.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=123)\n",
    "\n",
    "# Normalizando as variáveis preditoras\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape)\n",
    "print('Tamanho de X_test: ', X_test.shape)\n",
    "print('Tamanho de y_train: ', y_train.shape)\n",
    "print('Tamanho de y_test: ', y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:graduacao]",
   "language": "python",
   "name": "conda-env-graduacao-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
